{
  "model": "meta-llama/Llama-3.1-8B-Instruct",
  "dgx_cost_per_hour": 0.07,
  "image_tag": "ghcr.io/elizabetht/token-labs/vllm-serve:latest",
  "prefill": {
    "tokens_per_second": 0,
    "cost_per_million_tokens": 0
  },
  "decode": {
    "tokens_per_second": 0,
    "cost_per_million_tokens": 0
  },
  "timestamp": null,
  "_note": "This file is auto-updated by the deploy-and-benchmark workflow"
}
